1 = Quickstart with AKS
2 
3 This is a quickstart guide for deploying TigerGraph single servers and clusters in Kubernetes on Azure Kubernetes Service(AKS).
4 
5 * xref:quickstart-with-aks.adoc#_single_server_deployment[Single-server deployment]
6 * xref:quickstart-with-aks.adoc#_cluster_deployment[Cluster-deployment]
7 
8 == Before you begin
9 
10 * Provision Kubernetes cluster on AKS with nodes that meet the xref:installation:hw-and-sw-requirements.adoc[hardware and software requirements] to run TigerGraph.
11 * https://kubernetes.io/docs/tasks/tools/[Install `kubectl` on your machine,] and make sure your local `kubectl` version is within one minor version's difference from the `kubectl` version on your cluster.
12 * https://docs.microsoft.com/en-us/azure/aks/kubernetes-walkthrough#connect-to-the-cluster[Configure `kubectl` for ASK cluster access].
13 
14 == Single-server deployment
15 
16 This section describes the steps to deploy, verify, and remove a single-server deployment of TigerGraph on AKS.
17 
18 === Deploy single server
19 
20 *Step 1: Generate deployment manifest*. Clone the https://github.com/tigergraph/ecosys.git[TigerGraph ecosystems repository] and change into the `k8s` directory. You can edit the `kustimization.yaml` file in the `aks` folder to change the namespace and image name for your deployment. The default namespace is `default`, and the default image is the official docker image for TigerGraph 3.2.0. No need to edit the files if no changes are needed.
21 
22 Next, run the `./tg` script in the `k8s` directory to generate the deployment manifest for a single-server deployment. A `deploy` directory will be created automatically and you should find the manifest named `tigergraph-aks.yaml` in the directory.
23 
24 [source,text]
25 ----
26 ./tg aks kustomize -s 1
27 ----
28 
29 *Step 2: Deploy manifest*. Run `kubectl apply` to create the deployment using the manifest you generated in step 1.
30 
31 [source,text]
32 ----
33 kubectl apply -f deploy/tigergraph-aks.yaml
34 ----
35 
36 === Verify single server
37 
38 After you create the deployment, run `kubectl get pods` to verify that the pods were created successfully.
39 
40 [source,text]
41 ----
42 $ kubectl get pods
43 NAME              READY   STATUS    RESTARTS   AGE
44 installer-zsnb4   1/1     Running   0          4m11s
45 tigergraph-0      1/1     Running   0          4m10s
46 ----
47 
48 Run `kubectl describe service/tg-external-service` to find the IP address of the load balancer. You can then make curl calls to port 9000 to make sure that RESTPP is running:
49 
50 [source,text]
51 ----
52 $ curl <load_balancer_ip>:9000/echo | jq .
53   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
54                                  Dload  Upload   Total   Spent    Left  Speed
55 100    39  100    39    0     0    120      0 --:--:-- --:--:-- --:--:--   120
56 {
57   "error": false,
58   "message": "Hello GSQL"
59 }
60 ----
61 
62 You can also copy the IP address into your browser and visit port 14240 to make sure that GraphStudio is working.
63 
64 === Connect to single server
65 
66 You can use `kubectl` to get a shell to the container or log in via `ssh`
67 
68 [source,text]
69 ----
70 # Via kubectl
71 kubectl exec -it tigergraph-0 -- /bin/bash
72 
73 # Via ssh
74 ip_m1=$(kubectl get pod -o wide |grep tigergraph-0| awk '{print $6}')
75 ssh tigergraph@ip_m1
76 ----
77 
78 === Remove single server resources
79 
80 Run the command below to delete all cluster resources:
81 
82 [source,text]
83 ----
84 $ kubectl delete -f deploy/tigergraph-aks.yaml && kubectl delete pvc -l app=tigergraph
85 ----
86 
87 == Cluster deployment
88 
89 This section describes the steps to deploy, verify, and delete a TigerGraph cluster in Kubernetes on AKS.
90 
91 === Deploy TigerGraph cluster
92 
93 ==== 1. Generate Kubernetes manifest
94 
95 Clone the https://github.com/tigergraph/ecosys.git[TigerGraph ecosystem repository] and change into the `k8s` directory:
96 
97 [source,text]
98 ----
99 $ git clone https://github.com/tigergraph/ecosys.git
100 $ cd ecosys/k8s
101 ----
102 
103 You can customize your deployment by editing the `kustomize.yaml` file in the `aks` directory. The `tg` script in the `k8s` folder offers a convenient way to make common customizations such as namespace, TigerGraph version, as well as cluster size. Run `./tg -h` to view the help text on how to use the script.
104 
105 Use the `tg` script in the `k8s` directory of the repo to create a Kubernetes manifest. Use `-s` or `--size` to indicate the number of nodes in the cluster. Use the `--ha` option to indicate the replication factor of the cluster, and the partitioning factor will be the number of nodes divided by the replication factor.
106 
107 For example, the following command will create a manifest that will deploy a 3*2 cluster with a replication factor of 2 and a partitioning factor of 3.
108 
109 [source,text]
110 ----
111 $ ./tg aks kustomize -s 6 --ha 2
112 ----
113 
114 The command will create a directory named `deploy` with the manifest inside.
115 
116 ==== 2. Deploy the cluster
117 
118 Run `kubectl apply` to create the deployment
119 
120 [source,text]
121 ----
122 $ kubectl apply -f ./deploy/tigergraph-aks.yaml
123 ----
124 
125 === Verify cluster
126 
127 Run `kubectl get pods` to verify the pods were created successfully:
128 
129 [source,text]
130 ----
131 kubectl get pods
132 NAME              READY   STATUS    RESTARTS   AGE
133 installer-zsnb4   1/1     Running   0          4m11s
134 tigergraph-0      1/1     Running   0          4m10s
135 tigergraph-1      1/1     Running   0          75s
136 ----
137 
138 Run `kubectl describe service/tg-external-service` to find the IP address of the load balancer for your AKS cluster. You can make a curl call to port 9000 to make sure that RESTPP is working:
139 
140 [source,text]
141 ----
142 $ curl <load_balancer_ip>:9000/echo | jq .
143   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
144                                  Dload  Upload   Total   Spent    Left  Speed
145 100    39  100    39    0     0    120      0 --:--:-- --:--:-- --:--:--   120
146 {
147   "error": false,
148   "message": "Hello GSQL"
149 }
150 ----
151 
152 You can also copy the IP address into your browser and visit port 14240 to make sure that GraphStudio is working.
153 
154 === Connect to instances
155 
156 You can use `kubectl` to get a shell to the container or log in via `ssh`
157 
158 [source,text]
159 ----
160 # Via kubectl
161 kubectl exec -it tigergraph-0 -- /bin/bash
162 
163 # Via ssh
164 ip_m1=$(kubectl get pod -o wide |grep tigergraph-0| awk '{print $6}')
165 ssh tigergraph@ip_m1
166 ----
167 
168 === Delete cluster resources
169 
170 Run the command below to delete all cluster resources:
171 
172 [source,text]
173 ----
174 $ kubectl delete -f deploy/tigergraph-aks.yaml && kubectl delete pvc -l app=tigergraph
175 ----

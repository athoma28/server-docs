1 = Troubleshooting Guide
2 :pp: {plus}{plus}
3 
4 [CAUTION]
5 ====
6 This troubleshooting guide is only up to date for v2.6 and below. +
7 Additional guidance for v3.0+ is in development.
8 ====
9 
10 == Introduction
11 
12 The Troubleshooting Guide teaches you how to monitor the status of your TigerGraph system, and when needed, find the log files in order to get a better understanding of why certain errors are occurring. This section covers log file debugging for data loading and querying.
13 
14 == General
15 
16 Before any deeper investigation, always run these general system checks :
17 
18 [source,text]
19 ----
20 $ gadmin status        (Make sure all TigerGraph services are UP.)
21 
22 $ df -lh               (Make sure all servers are getting enough disk space.)
23 
24 $ free -g              (Make sure all servers have enough memory.)
25 
26 $ tsar                 (Make sure there is no irregular memory usage on the system.)
27 
28 $ dmesg -T | tail      (Make sure there are no Out of Memory, or any other errors.)
29 
30 $ grun all "date"      (Make sure the time across all nodes are synchronized
31                         with time difference under 2 seconds. )
32 ----
33 
34 === Location of Log Files
35 
36 The following command reveals the location of the log files :
37 
38 [source,text]
39 ----
40 gadmin log
41 ----
42 
43 You will be presented with a list of log files. The left side of the resulting file paths is the component for which the respective log file is logging information. The majority of the time, these files will contain what you are looking for. You may notice that there are multiple files for each TigerGraph component.
44 
45 [NOTE]
46 ====
47 The .out file extension is for errors. +
48 The .INFO file extension is for normal behaviors.
49 ====
50 
51 In order to diagnose an issue for a given component, you'll want to check the .out log file extension for that component.
52 
53 image::https://lh5.googleusercontent.com/6MnNakec5fKh5faCoWdZwfzprqXyguDZXt15nz0QAG1M3vW1t0nmwo7oYr3DgwVsgJoIEjub-5tSA81UtOQ-Ot-9m30zZ9Zr5tRG077dgfZ7KaE3tMMafUK63oi6fILQeM-kQw6fKqc[]
54 
55 Other log files that are not listed by the *`gadmin log`* command are those for Zookeeper and Kafka, which can be found here:
56 
57 [source,text]
58 ----
59 zookeeper : ~/tigergraph/zk/zookeeper.out.*
60 kafka     : ~/tigergraph/kafka/kafka.out
61 ----
62 
63 === Synchronize time across nodes in a cluster
64 
65 TigerGraph will experience a variety of issues if clocks across different nodes in a cluster are out of sync. If running `grun all "date"` shows that the clocks are out of sync, it is highly recommended that you install NTP implementations such as https://chrony.tuxfamily.org/index.html[`chrony`] or http://manpages.ubuntu.com/manpages/xenial/man8/systemd-timesyncd.service.8.html[`timesyncd`] to keep them in sync.
66 
67 == Installation Error Debugging
68 
69 === Missing Dependencies
70 
71 The installation will quit if there are any missing dependency packages, and output a message. Please run `bash install_tools.sh` to install all missing packages. You will need an internet connection to install the missing dependencies.
72 
73 === Pinpoint The Failed Step
74 
75 Using the -x flag during installation will show you the detailed shell commands being run during installation. +
76 `bash -x install.sh`
77 
78 === Disk Space Errors
79 
80 * The `/home` directory requires at least 200MB of space, or the installation will fail with an out of disk message. This is temporary only during installation and will be moved to the root directory once installation is complete.
81 * The `/tmp` directory requires at least 1GB of space, or the installation will fail with an out of disk message
82 * The directory in which you choose to install TigerGraph requires at least 20GB of space, or the installation will report the error and exit.
83 
84 === Firewall Errors
85 
86 If your firewall blocks all ports not defined for use, we recommend opening up internal ports 1000-50000.
87 
88 If you are using a cloud instance, you will need to configure the firewall rules through the respective consoles. +
89 e.g. Amazon AWS or Microsoft Azure +
90 If you are managing a local machine, you can manage your open ports using the `iptables` command. Please refer to the example below to help with your firewall configuration.
91 
92 [source,text]
93 ----
94 # iptables help page
95 $ sudo iptables -h
96 
97 # This will list your firewall rules
98 $ sudo iptables -L
99 
100 # Allow incoming SSH connections to port 22 from the 192.168.0.0 subnet
101 $ sudo iptables -A INPUT -p tcp --dport 22 -s 192.168.0.0/24 -j ACCEPT
102 $ sudo iptables -A INPUT -p tcp --dport 22 -s 127.0.0.0/8 -j ACCEPT
103 $ sudo iptables -A INPUT -p tcp --dport 22 -j DROP
104 ----
105 
106 == Query Debugging
107 
108 === Checking the Logs - Flow of a query in the system
109 
110 To better help you understand the flow of a query within the TigerGraph system, we've provided the diagram below with arrows showing the direction of information flow. We'll walk through the execution of a typical query to show you how to observe the information flow as recorded in the log files.
111 
112 image::screen-shot-2020-03-27-at-2.19.19-pm.png[]
113 
114 From calling a query to returning the result, here is how the information flows:
115 
116 . Nginx receives the request.
117 
118 [source,text]
119 ----
120 grep <QUERY_NAME> /home/tigergraph/tigergraph/logs/nginx/ngingx_1.access.log
121 ----
122 
123 [NOTE]
124 ====
125 You can click on the image below to expand it.
126 ====
127 
128 image::https://lh5.googleusercontent.com/n2ehgN21jrvzuXUj2JJmg-xxqwj4o7Dlc_f1oPAAJDAmxv-1KLwyblrfS4FkWq2vOwHsAVbxYYt2qI_EcG9e4sWEGOSvVjCXtb5yFObazfzBEnVh5juPICoUA2Rc0iseifiCHfDllrE[]
129 
130 . Nginx sends the request to Restpp.
131 
132 [source,text]
133 ----
134 grep <QUERY_NAME> /home/tigergraph/tigergraph/logs/RESTPP_1_1/log.INFO
135 ----
136 
137 image::screen-shot-2020-03-24-at-5.14.06-pm.png[]
138 
139 . Restpp sends an ID translation task to GSE and a query request to GPE.
140 . GSE sends the translated ID to GPE, and the GPE starts to process the query.
141 . GPE sends the query result to Restpp, and sends a translation task to GSE, which then sends the translation result to Restpp.
142 
143 [source,text]
144 ----
145 grep <REQUEST_ID> /home/tigergraph/tigergraph/logs/GPE_1_1/log.INFO
146 ----
147 
148 image::screen-shot-2020-03-27-at-2.06.51-pm.png[]
149 
150 [source,text]
151 ----
152 grep <REQUEST_ID> /home/tigergraph/tigergraph/logs/GSE_1_1/log.INFO
153 ----
154 
155 image::screen-shot-2020-03-24-at-5.22.23-pm.png[]
156 
157 . Restpp sends the result back to Nginx.
158 
159 [source,text]
160 ----
161 grep <REQUEST_ID> /home/tigergraph/tigergraph/logs/RESTPP_1_1/log.INFO
162 ----
163 
164 image::https://lh6.googleusercontent.com/idUWKQ_1kIkOjwGmjSM7VzbkJGGJaWYrLtExpkTvOuXsDnv5wvDch31dnzsvFy7DZ_T28hWY-BKMJSbmitH6BRjTjXqA27FPXLVyFWDKlUJHdZqlVT5_XePil7TlMPM7HxUpdBpGjzM[]
165 
166 . Nginx sends the response.
167 
168 [source,text]
169 ----
170 grep <QUERY_NAME> /home/tigergraph/tigergraph/logs/nginx/nginx_1.access.log
171 ----
172 
173 image::screen-shot-2020-03-24-at-5.26.46-pm.png[]
174 
175 === Other Useful Commands for Query Debugging
176 
177 [source,text]
178 ----
179 Check recently executed query:
180 $ grep UDF:: /home/tigergraph/tigergraph/logs/GPE_1_1/log.INFO | tail -n 50
181 
182 Get the number of queries executed recently:
183 $ grep UDF::End /home/tigergraph/tigergraph/logs/GPE_1_1/log.INFO | wc -l
184 
185 Grep distributed query log:
186 $ grep “Action done” /home/tigergraph/tigergraph/logs/GPE_1_1/log.INFO | tail -n 50
187 
188 
189 Grep logs from all servers:
190 $ grun all “grep UDF:: /home/tigergraph/tigergraph/logs/GPE_*/log.INFO | tail -n 50”
191 ----
192 
193 === Slow Query Performance
194 
195 Multiple situations can lead to slower than expected query performance:
196 
197 * *Insufficient Memory* When a query begins to use too much memory, the engine will start to put data onto the disk, and memory swapping will also kick in. Use the Linux command: *`free -g`* to check available memory and swap status, or you can also xref:troubleshooting-guide.adoc#_how_to_monitor_memory_usage_by_query[monitor the memory usage of specific queries through GPE logs]. To avoid running into insufficient memory problems, optimize the data structure used within the query or increase the physical memory size on the machine.
198 * *GSQL Logic* Usually, a single server machine can process up to 20 million edges per second. If the actual number of vertices or edges is much much lower,  most of the time it can be due to inefficient query logic. That is, the query logic is now following the natural execution of GSQL. You will need to optimize your query to tune the performance.
199 * *Disk IO* When the query writes the result to the local disk, the disk IO may be the bottleneck for the query's performance. Disk performance can be checked with this Linux command : *`sar 1 10`*. If you are writing (PRINT) one line at a time and there are many lines, storing the data in one data structure before printing may improve the query performance.
200 * *Huge JSON Response* If the JSON response size of a query is too massive, it may take longer to compose and transfer the JSON result than to actually traverse the graph. To see if this is the cause, check the GPE log.INFO file. If the query execution is already completed in GPE but has not been returned, and CPU usage is at about 200%, this is the most probable cause. If possible, please reduce the size of the JSON being printed.
201 * *Memory Leak* This is a very rare issue. The query will progressively become slower and slower, while GPE's memory usage increases over time. If you experience these symptoms on your system, please report this to the TigerGraph team.
202 * *Network Issues* When there are network issues during communication between servers, the query can be slowed down drastically. To identify that this is the issue, you can check the CPU usage of your system along with the GPE log.INFO file. If the CPU usage stays at a very low level and GPE keeps printing `???` , it means network IO is very high.
203 * *Frequent Data Ingestion in Small Batches* Small batches of data can increase the data loading overhead and query processing workload. Please increase the batch size to prevent this issue.
204 
205 === Query Hangs
206 
207 When a query hangs or seems to run forever, it can be attributed to these possibilities :
208 
209 * *Services are down* Please check that TigerGraph services are online and running. Run *`gadmin status`* and possibly check the logs for any issues that you find from the status check.
210 * *Query is in an infinite loop* To verify this is the issue, check the GPE log.INFO file to see if graph iteration log lines are continuing to be produced. If they are, and the edgeMaps log the same number of edges every few iterations, you have an infinite loop in your query.  If this is the case, please restart GPE to stop the query : *`gadmin restart gpe -y`*. Proceed to refine your query and make sure your loops within the query are able to break out of the loop.
211 * *Query is simply slow* If you have a very large graph, please be patient. Ensure that there is no infinite loop in your query, and refer to the xref:troubleshooting-guide.adoc#_slow_query_performance[slow query performance] section for possible causes.
212 * *GraphStudio Error* If you are running the query from GraphStudio, the loading bar may continue spinning as if the query has not finished running. You can right-click the page and select _inspect->console_ (in the Google Chrome browser) __and try to find any suspicious errors there.
213 
214 === Query Returns No Result
215 
216 If a query runs and does not return a result, it could be due to two reasons:
217 
218 . Data is not loaded. +
219 From the Load Data page on GraphStudio, you are able to check the number of loaded vertices and edges, as well as the number of each vertex or edge type. Please ensure that all the vertices and edges needed for the query are loaded.
220 . Properties are not loaded. +
221 The number of vertices and edges traversed can be observed in the GPE log.INFO file. If for one of the iterations you see *activated 0 vertices*, this means no target vertex satisfied your searching condition. For example, the query can fail to pass a WHERE clause or a HAVING clause.
222 
223 If you see *0 vertex reduces* while the edge map number is not 0, that means that all edges have been filtered out by the `WHERE` clause, and that no vertices have entered into the `POST-ACCUM` phase. If you see more than 0 vertex reduces, but *activated 0 vertices*, this means all the vertices were filtered out by the `HAVING` clause.
224 
225 To confirm the reasoning within the log file, use GraphStudio to pick a few vertices or edges that should have satisfied the conditions and check their attributes for any unexpected errors.
226 
227 === Query Installation Failed
228 
229 Query Installation may fail for a handful of reasons. If a query fails to install, please check the GSQL log file. The default location for the GSQL log is here :
230 
231 [source,text]
232 ----
233 /home/tigergraph/tigergraph/logs/gsql_server_log/GSQL_LOG
234 ----
235 
236 Go down to the last error and it will point you to the error. This will show you any query errors that could be causing the failed installation. If you have created a xref:3.2@gsql-ref:querying:func/query-user-defined-functions.adoc[user-defined function], you could potentially have a c{pp} compilation error.
237 
238 [WARNING]
239 ====
240 If you have a c{pp} user-defined function error, your query will fail to install, even if it does not utilize the UDF.
241 ====
242 
243 === *Debugging Memory-related Failures*
244 
245 ==== *How to monitor memory usage by query*
246 
247 GPE records memory usage by query at different stages of the query and saves it to `$(gadmin config get System.LogRoot)/gpe/log.INFO`. You can monitor how much memory a query is using by searching the log file for the request ID and filter for lines that contain `"QueryMem"`:
248 
249 [source,text]
250 ----
251 grep -i <request_id> $(gadmin config get System.LogRoot)/gpe/log.INFO |
252     grep -i "querymem"
253 ----
254 
255 You can also run a query first, and then run the following command immediately after to retrieve the most recent query logs and filter for `"QueryMem"`:
256 
257 [source,text]
258 ----
259 tail -n 50 $(gadmin config get System.LogRoot)/gpe/log.INFO |
260     grep -i "querymem"
261 ----
262 
263 You will get results that look like the following, which shows memory usage by the query at different stages of its execution. The number at the end of each line indicates the number of bytes of memory utilized by the query:
264 
265 [source,text]
266 ----
267 0415 01:33:40.885433  6553 gpr.cpp:195] Engine_MemoryStats|     \
268 ldbc_snb::,196612.RESTPP_1_1.1618450420870.N,NNN,15,0,0|        \
269 MONITORING Step(1) BeforeRun[GPR][QueryMem]: 116656
270 
271 I0415 01:33:42.716199  6553 gpr.cpp:241] Engine_MemoryStats|    \
272 ldbc_snb::,196612.RESTPP_1_1.1618450420870.N,NNN,15,0,0|        \
273 MONITORING Step(1) AfterRun[GPR][QueryMem]: 117000
274 ----
275 
276 ==== *How to check system free memory percentage*
277 
278 You can check how much free memory your system has as a percentage of its total memory by running the following command:
279 
280 [source,text]
281 ----
282 tail -n 50 $(gadmin config get System.LogRoot)/gpe/log.INFO | grep -i 'freepct'
283 ----
284 
285 The number following `"FreePct"` indicates the percentage of the system free memory. The following example shows the system free memory is 69%:
286 
287 [source,text]
288 ----
289 I0520 23:40:09.845811  7828 gsystem.cpp:622]
290 System_GSystem|GSystemWatcher|Health|ProcMaxGB|0|ProcAlertGB|0|
291 CurrentGB|1|SysMinFreePct|10|SysAlertFreePct|30|FreePct|69
292 ----
293 
294 When free memory drops below 10 percent (`SysMinFreePct`), all queries are aborted. This threshold is adjustable through xref:gadmin:management-with-gadmin.adoc#_gadmin_config[`gadmin config`].
295 
296 ==== *How to retrieve information on queries aborted due to memory usage*
297 
298 [source,text]
299 ----
300  log:W0312 02:10:57.839139 15171 scheduler.cpp:116] System Memory in Critical state. Aborted.. Aborting.
301 ----
302 
303 == Data Loading Debugging
304 
305 === Checking the Logs
306 
307 ==== GraphStudio
308 
309 Using GraphStudio, you are able to see, from a high-level, a number of errors that may have occurred during the loading. This is accessible from the Load Data page. +
310 Click on one of your data sources, then click on the second tab of the graph statistics chart. There, you will be able to see the status of the data source loading, number of loaded lines, number of lines missing, and lines that may have an incorrect number of columns. (Refer to picture below.)
311 
312 image::screen-shot-2020-03-25-at-3.50.12-pm.png[]
313 
314 ==== Command Line
315 
316 If you see there are a number of issues from the GraphStudio Load Data page, you can dive deeper to find the cause of the issue by examining the log files. Check the loading log located here:
317 
318 [source,text]
319 ----
320 /home/tigergraph/tigergraph/logs/restpp/restpp_loader_logs/<GRAPH_NAME>/
321 ----
322 
323 Open up the latest *.log* file and you will be able to see details about each data source. The picture below is an example of a correctly loaded data file.
324 
325 image::screen-shot-2020-03-27-at-1.59.24-pm.png[]
326 
327 Here is an example of a loading job with errors :
328 
329 image::screen-shot-2020-03-25-at-3.58.24-pm.png[]
330 
331 From this log entry, you are able to see the errors being marked as lines with invalid attributes. The log will provide you the line number from the data source which contains the loading error, along with the attribute it was attempting to load to.
332 
333 === Slow Loading
334 
335 Normally, a single server running TigerGraph will be able to load from 100k to 1000k lines per second, or 100GB to 200GB of data per hour. This can be impacted by any of the following factors:
336 
337 * *Loading Logic* How many vertices/edges are generated from each line loaded?
338 * *Data Format*  Is the data formatted as JSON or CSV? Are multi-level delimiters in use? Does the loading job intensively use temp_tables?
339 * *Hardware Configuration* Is the machine set up with HDD or SSD? How many CPU cores are available on this machine?
340 * *Network Issue* Is this machine doing local loading or remote POST loading? Any network connectivity issues?
341 * *Size of Files* How large are the files being loaded? Many small files may decrease the performance of the loading job.
342 * *High Cardinality Values Being Loaded to String Compress Attribute Type* How diverse is the set of data being loaded to the String Compress attribute?
343 
344 To combat the issue of slow loading, there are also multiple methods:
345 
346 * If the computer has many cores, consider increasing the number of Restpp load handlers.
347 
348 [source,text]
349 ----
350 $ gadmin --config handler
351 increase the number of handlers
352 save
353 $ gadmin --config apply
354 ----
355 
356 * Separate *`~/tigergraph/kafka`* from *`~/tigergraph/gstore`* and store them on separate disks.
357 * Do distributed loading.
358 * Do offline batch loading.
359 * Combine many small files into one larger file.
360 
361 === Loading Hangs
362 
363 When a loading job seems to be stuck, here are things to check for :
364 
365 * *GPE is DOWN* You can check the status of GPE with this command : *`gadmin status gpe`* If GPE is down, you can find the logs necessary with this command : *`gadmin log -v gpe`*
366 * *Memory is full* Run this command to check memory usage on the system : *`free -g`*
367 * *Disk is full* Check disk usage on the system : *`df -lh`*
368 * *Kafka is DOWN* You can check the status of Kafka with this command : *`gadmin status kafka`* If it is down, take a look at the log with this command : *`vim ~/tigergraph/kafka/kafka.out`*
369 * *Multiple Loading Jobs* By default, the Kafka loader is configured to allow a single loading job. If you execute multiple loading jobs at once, they will run sequentially.
370 
371 === Data Not Loaded
372 
373 If  the loading job completes, but data is not loaded, there may be issues with the data source or your loading job. Here are things to check for:
374 
375 * Any invalid lines in the data source file. Check the log file for any errors. If an input value does not match the vertex or edge type, the corresponding vertex or edge will not be created.
376 * Using quotes in the data file may cause interference with the tokenization of elements in the data file. Please check the GSQL Language Reference section under xref:3.2@gsql-ref:ddl-and-loading:creating-a-loading-job.adoc#_other_optional_load_clauses[Other Optional LOAD Clauses]. Look for the QUOTE parameter to see how you should set up your loading job.
377 * Your loading job loads edges in the incorrect order. When you defined the graph schema, the *from*  and *to* vertex order will affect the way you write the loading job. If you wrote the loading job in reversed order, the edges will not be created, possibly also affecting the population of vertices.
378 
379 === Loading is Incorrect
380 
381 If you know what data you expect to see (number of vertices and edges, and attribute values), but the loaded data does not mean your expectations, there are a number of possible causes to investigate:
382 
383 . First, check the logs for important clues.
384 . Are you reaching and reading all the data sources (paths and permissions)?
385 . Is the data mapping correct?
386 . Are your data fields correct?  In particular, check data types. For strings, check for unwanted extra strings. Leading spaces are not removed unless you apply an optional token function to trim the extra spaces.
387 . Do you have duplicate ids, resulting in the same vertex or edge being loading more than once.  Is this intended or unintended?  TigerGraph's default loading semantics is UPSERT.  Check the loading documentation to maker sure you understand the semantics in detail:
388 +
389 https://docs.tigergraph.com/dev/gsql-ref/ddl-and-loading/creating-a-loading-job#cumulative-loading
390 
391 === Loading Failure
392 
393 Possible causes of a loading job failure are:
394 
395 * *Loading job timed out* If a loading job hangs for 600 seconds, it will automatically time out.
396 * *Port Occupied* Loading jobs require port 8500. Please ensure that this port is open.
397 
398 == Schema Change Debugging
399 
400 This section will only cover the debugging schema change jobs, for more information about schema changes, please read the xref:3.2@gsql-ref:ddl-and-loading:modifying-a-graph-schema.adoc[Modifying a Graph Schema] page.
401 
402 Understanding what happens behind the scenes during a schema change.
403 
404 . *DSC (Dynamic Schema Change) Drain* - Stops the flow of traffic to RESTPP and GPE If GPE receives a DRAIN command, it will wait 1 minute for existing running queries to finish up. If the queries do not finish within this time, the DRAIN step will fail, causing the schema change to fail.
405 . *DSC Validation* - Verification that no queries are still running.
406 . *DSC Apply* - Actual step where the schema is being changed.
407 . *DSC Resume* - Traffic resumes after schema change is completed. Resume will automatically happen if a schema change fails. RESTPP comes back online. All buffered query requests will go through after RESTPP resumes, and will use the new updated schema.
408 
409 [CAUTION]
410 ====
411 Schema changes are not recommended for production environments. +
412 Even if attributes are deleted, TigerGraph's engine will still scan all previous attributes. We recommend limiting schema changes to dev environments.
413 
414 Schema changes are all or nothing. If a schema change fails in the middle, changes will not be made to the schema.
415 ====
416 
417 === Signs of Schema Change Failure
418 
419 * Failure when creating a graph
420 * Global Schema Change Failure
421 * Local Schema Change Failure
422 * Dropping a graph fails
423 * If GPE or RESTPP fail to start due to YAML error, please report this to TigerGraph.
424 
425 If you encounter a failure, please take a look at the GSQL log file : `gadmin log gsql`. Please look for these error codes:
426 
427 * *Error code 8* - The engine is not ready for the snapshot. Either the pre-check failed or snapshot was stopped. The system is in critical non-auto recoverable error state. Manual resolution is required. Please contact TigerGraph support.
428 * *Error code 310* - Schema change job failed and the proposed change has not taken effect. This is the normal failure error code.  Please see next section for failure reasons.
429 
430 === Reasons For Dynamic Schema Change Failure
431 
432 * *Another schema change or a loading job is running*. This will cause the schema change to fail right away.
433 * *GPE is busy.* Potential reasons include :
434  ** Long running query.
435  ** Loading job is running.
436  ** Rebuild process is taking a long time.
437 * *Service is down.* (RESTPP/GPE/GSE)
438 * *Cluster system clocks are not in sync.* Schema change job will think the request is stale, causing this partition's schema change to fail.
439 * *Config Error.* If the system is shrunk manually, schema change will fail.
440 
441 === Log Files
442 
443 You will need to check the logs in this order : GSQL log, admin_server log, service log. +
444 Admin_server log files can be found here : `~/tigergraph/logs/admin_server/` You will want to take a look at the INFO file. +
445 The service log is each of the services respectively. `gadmin log <service_name>` will show you the location of these log files.
446 
447 ==== Example of a successful schema change job. (admin_server log)
448 
449 [source,text]
450 ----
451 $ grep DSC ~/tigergraph/logs/admin_server/INFO.20181011-101419.98774
452 
453 I1015 12:04:14.707512 116664 gsql_service.cpp:534] Notify RESTPP DSCDrain successfully.
454 I1015 12:04:15.765108 116664 gsql_service.cpp:534] Notify GPE DSCDrain successfully.
455 I1015 12:04:16.788666 116664 gsql_service.cpp:534] Notify GPE DSCValidation successfully.
456 I1015 12:04:17.805620 116664 gsql_service.cpp:534] Notify GSE DSCValidation successfully.
457 I1015 12:04:18.832386 116664 gsql_service.cpp:534] Notify GPE DSCApply successfully.
458 I1015 12:04:21.270011 116664 gsql_service.cpp:534] Notify RESTPP DSCApply successfully.
459 I1015 12:04:21.692147 116664 gsql_service.cpp:534] Notify GSE DSCApply successfully.
460 ----
461 
462 ==== Example of DSC fail
463 
464 [source,text]
465 ----
466 E1107 14:13:03.625350 98794 gsql_service.cpp:529] Failed to notify RESTPP with command: DSCDrain. rc: kTimeout. Now trying to send Resume command to recover.
467 E1107 14:13:03.625562 98794 gsql_service.cpp:344] DSC failed at Drain stage, rc: kTimeout
468 E1107 14:14:03.814132 98794 gsql_service.cpp:513] Failed to notify RESTPP with command: DSCResume. rc: kTimeout
469 ----
470 
471 In this case, we see that RESTPP failed at the DRAIN stage. We need to first look at whether RESTPP services are all up. Then, verify that the time of each machine is the same. If all these are fine, we need to look at RESTPP log to see why it fails. Again, use the "DSC" keyword to navigate the log.
472 
473 == GSE Error Debugging
474 
475 To check the status of GSE, and all other processes, run `gadmin status` to show the status of key TigerGraph processes. As with all other processes, you are able to find the log file locations for GSE by the `gadmin log` command. Refer to the link:[Location of Log Files] for more information about which files to check.
476 
477 [source,text]
478 ----
479 $ gadmin log gse
480 [Warning] License will expire in 5 days
481 GSE : /home/tigergraph/tigergraph/logs/gse/gse_1_1.out
482 GSE : /home/tigergraph/tigergraph/logs/GSE_1_1/log.INFO
483 ----
484 
485 === GSE Process Fails To Start
486 
487 If the GSE process fails to start, it is usually attributed to a license issue, please check these factors :
488 
489 * *License Expiration* `gadmin status license` This command will show you the expiration date of your license.
490 * *Single Node License on a Cluster* If you are on a TigerGraph cluster, but using a license key intended for a single machine, this will cause issues. Please check with your point of contact to see which license type you have.
491 * *Graph Size Exceeds License Limit* Two cases may apply for this reason. The first reason is you have multiple graphs but your license only allows for a single graph. The second reason is that your graph size exceeds the memory size that was agreed upon for the license. Please check with your point of contact to verify this information.
492 
493 === *GSE status is "not_ready"*
494 
495 Usually in this state, GSE is warming up. This process can take quite some time depending on the size of your graph.
496 
497 <INCLUDE PROCESS NAME SHOWING CPU USAGE TO VERIFY THE "WARMING UP" STATE>
498 
499 [NOTE]
500 ====
501 Very rarely, this will be a ZEROMQ issue. Restarting TigerGraph should resolve this issue
502 
503 `gadmin restart -y`
504 ====
505 
506 === GSE crash
507 
508 GSE crashes are likely due to and Out Of Memory issue. Use the `dmesg -T` command to check any errors.
509 
510 [WARNING]
511 ====
512 If GSE crashes, and there are no reports of OOM, please reach out to TigerGraph support.
513 ====
514 
515 === GSE High Memory Consumption
516 
517 If your system has unexpectedly high memory usage, here are possible causes :
518 
519 * *Length of ID strings is too long* GSE will automatically deny IDs with a length longer than 16k. Memory issues could also arise if an ID string is too long ( > 500). One proposed solution to this is to hash the string.
520 * *Too Many Vertex Types* Check the number of unique vertex types in your graph schema. If your graph schema requires more than 200 unique vertex types, please contact TigerGraph support.
521 
522 == GraphStudio Debugging
523 
524 === Browser Crash / Freeze
525 
526 If your browser crashes or freezes (shown below), please refresh your browser.
527 
528 image::https://lh6.googleusercontent.com/3vmIx6BF3S0YuwLQ9-PrKip5c-Bh15NymmAlGh83cILcMGu7v3wzc23cnMlKAlSuFDjz7ZOGmhg82wUZgeIlG7xb1F0OC6yhstBQEcmRN3rl95O_s1qoGbwiqnaczvg1Y63DTDbYtN4[]
529 
530 === GraphStudio Crash
531 
532 If you suspect GraphStudio has crashed, first run `gadmin status` to verify all the components are in good shape. Two known causes of GraphStudio crashes are :
533 
534 * *Huge JSON response* User-written queries can return very large JSON responses. If GraphStudio often crashes on large query responses, you can try reducing the size limit for JSON responses by changing the `GUI.RESTPPResponseMaxSizeBytes` configuration using xref:gadmin:management-with-gadmin.adoc#_gadmin_config[`gadmin config`]. The default limit is 33554432 bytes.
535 
536 [source,bash]
537 ----
538 $ gadmin config entry GUI.RESTPPResponseMaxSizeBytes
539 New: 33554431
540 [   Info] Configuration has been changed. Please use 'gadmin config apply' to persist the changes.
541 $ gadmin config apply
542 ----
543 
544 * *Very Dense Graph Visualization* On the Explore Graph page, the "Show All Paths" query on a very dense graph is known to cause a crash.
545 
546 === DEBUG mode
547 
548 To find the location of GraphStudio log files, use this command : `gadmin log gui`
549 
550 [source,text]
551 ----
552 $ gadmin log vis
553 [Warning] License will expire in 5 days
554 VIS : /home/tigergraph/tigergraph/logs/gui/gui_ADMIN.log
555 VIS : /home/tigergraph/tigergraph/logs/gui/gui_INFO.log
556 ----
557 
558 Allowing GraphStudio DEBUG mode will print out more information to the log files. To allow DEBUG mode, please edit the following file : `/home/tigergraph/tigergraph/visualization/server/src/config/local.json`
559 
560 image::https://lh3.googleusercontent.com/pVTzOYUGWao0YuAjKYr_r1tQNQ9y1zknf8txPThPNJm0nyTaBDok3kBvJ8a3RS2Dr7GnGPcX3HrKu47fbKfPuPWOqjvy12CkXCdYYZLrNvNtjCczwqJayk-QxXTuC5vZ72OSx3KE6BE[]
561 
562 image::https://lh5.googleusercontent.com/VQiOsJ1ez9s21h9QxtwqEAEbI28f6RNFlYt7UqCyVjKHfr2xgi9YbvksZYR1HETttrSLaFPr25FiP995ZRRSPdvb-UH8pjn2yp4w-8ODMpcvS52n1U3VoI70nFE5l0j1kelQRm6_hlI[]
563 
564 After editing the file, run `gadmin restart gui -y` to restart the GraphStudio service. Follow along the log file to see what is happening : `tail -f /home/tigergraph/tigergraph/logs/gui/gui_INFO.log`
565 
566 Repeat the error-inducing operations in GraphStudio and view the logs.
567 
568 ==== Known Issues
569 
570 There is a list of known GraphStudio issues xref:gui:graphstudio:known-issues.adoc[here].
571 
572 == Further Debugging
573 
574 If after taking these actions you cannot solve the issue, please reach out to support@tigergraph.com to request assistance.

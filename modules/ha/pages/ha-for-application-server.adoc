1 = High Availability Support for Application Server
2 
3 == Introduction
4 
5 TigerGraph supports native HA functionality for its application server, which serves the APIs for TigerGraph's GUI - GraphStudio and Admin Portal. The application server follows the active-active architecture, in which *the server is always on m1 and all replicas of m1*. If one server falls offline, you can use the other servers without any loss of functionality.
6 
7 When you deploy TigerGraph in a cluster with multiple replicas, it is ideal to set up load balancing to distribute network traffic evenly across the different servers. This page discusses what to do when a server dies when you haven't set up load balancing, and the steps needed to set up load balancing for the application server.
8 
9 image::diagram-draft-1-.svg[]
10 
11 == *When a server dies*
12 
13 When a server dies, users can proceed to the next available server within the cluster to resume the operations. For example, assuming the TigerGraph cluster has Application Server on m1 and m2. If the server on m1 dies, users can access m2 to use GraphStudio and Admin Portal.
14 
15 To find out which node hosts the application server, run https://docs.tigergraph.com/v/3.2/admin/admin-guide/system-management/advanced-platform-operations#show-deployment-information[the `gssh` command] in the bash terminal of any active node in the cluster. The output will show you which nodes are hosting a GUI server.
16 
17 Keep in mind that any long-running operation that is currently in process when the server dies will be lost.
18 
19 == Load Balancing
20 
21 When you deploy TigerGraph in a cluster with multiple replicas, it is ideal to set up load balancing to distribute network traffic evenly across the different servers.
22 
23 === Set up load balancing with Nginx
24 
25 One possible choice for setting up load balancing is through the use of Nginx.
26 
27 Here is an example Nginx configuration for the upstream and server directives:
28 
29 [source,text]
30 ----
31     upstream flask_pool {
32         ip_hash;
33         zone flask_pool 64k;
34         server 172.31.86.19:14240;
35         server 172.31.88.70:14240;
36         server 172.31.94.90:14240;
37 
38         keepalive 32;
39     }
40 
41     server {
42         listen      8000;
43         server_name localhost;
44 
45         location / {
46                 root html;
47                 index index.html index.htm;
48                 proxy_pass http://flask_pool;
49                 proxy_read_timeout 3600;
50                 proxy_set_header Connection "";
51                 proxy_http_version 1.1;
52                 chunked_transfer_encoding off;
53                 proxy_buffering off;
54                 proxy_cache off;
55         }
56         error_page 500 502 503 504 /50x.html;
57         location = /50x.html {
58                 root html;
59         }
60     }
61 ----
62 
63 The server directives should specify your nodes' addresses which you want to load balance. Since TigerGraph requires session persistence, the load balancing methods will be limited to _ip_hash_ or _hash_, unless you have access to Nginx Plus, which then means any load balancing method may be used with session persistence setup: https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/#sticky
64 
65 An active health check can be set on the following endpoint if using Nginx Plus:
66 
67 `/api/ping`
68 
69 Otherwise, only a passive health check is available. See Nginx documentation for more information: https://docs.nginx.com/nginx/admin-guide/load-balancer/http-health-check/
70 
71 === Set up AWS Elastic Load Balancer
72 
73 If your applications are provisioned on AWS, another choice for load balancing is through the use of an https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html[Application Load Balancer].
74 
75 To create an application load balancer, follow AWS's guide to https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-application-load-balancer.html[create an application load balancer]. The following configurations apply as you follow the guide:
76 
77 ==== Configure a security group
78 
79 When creating or using an existing security group in Step 3, make sure it allows requests from the load balancer to port 14240 of the instances in the target group.
80 
81 ==== Health check URL
82 
83 In Step 4, set the health check URL to `/api/ping`
84 
85 ==== Configure targets for the target group
86 
87 In Step 5, enter 14240 for the port of your instances.
88 
89 ==== Enable sticky sessions
90 
91 After following the steps and creating your load balancer, https://docs.aws.amazon.com/elasticloadbalancing/latest/application/sticky-sessions.html[enable sticky sessions] in your target group.
92 
93 After successfully creating your load balancer, you should now be able to access GraphStudio through the load balancer's DNS name. The DNS name can be found under the "Description" tab of your load balancer in the Amazon EC2 console.
94 
95 === Set up Azure Application Gateway
96 
97 If your instances are provisioned on Azure, you can set up an https://docs.microsoft.com/en-us/azure/application-gateway/overview[Application Gateway].
98 
99 Follow the steps for setting up an Application Gateway outlined here:https://docs.microsoft.com/en-us/azure/application-gateway/quick-create-portal[Quickstart: Direct web traffic using the portal - Azure Application Gateway]
100 
101 Some different TigerGraph specific settings are required during Application Gateway setup:
102 
103 * Under the section "`Configuration Tab`"
104  ** For step 5, where it states to use port 80 for the backend port, use port 14240 instead.
105  ** In the same window, enable "`Cookie-based affinity`".
106 
107 ==== Create a custom probe for Application Gateway
108 
109 After the Application Gateway is complete, we need to create a custom health probe in order to check the health/status of our Application Servers. You can follow the following steps outlined here:https://docs.microsoft.com/en-us/azure/application-gateway/application-gateway-create-probe-portal[Create a custom probe using the portal - Azure Application Gateway]
110 
111 When filling out the health probe information, the fields below should have the following values:
112 
113 *Pick port from backend HTTP settings:* yes
114 
115 *Path:* `/api/ping`
116 
117 *HTTP Settings:* The HTTP settings associated with the backend pool create during the Application Gateway setup
118 
119 After successfully creating the Application Gateway, you should now be able to access GraphStudio from the frontend IP associated with the Application Gateway.
120 
121 === Set up GCP External HTTP(s) Load Balancer
122 
123 If your instances are provisioned on Google Cloud, you can set up anhttps://cloud.google.com/load-balancing/docs/https[External HTTP(s) Load Balancer]:
124 
125 You can follow Google's provided steps in their documentation for setup here:https://cloud.google.com/iap/docs/load-balancer-howto[Setting up an external HTTPS load balancer  |  Identity-Aware Proxy]
126 
127 When https://cloud.google.com/iap/docs/load-balancer-howto#mig[creating the instance group]:
128 
129 * Click "`Specify port name mapping`", and use 14240 for the port
130 
131 When https://cloud.google.com/load-balancing/docs/health-checks[setting up the health check]:
132 
133 * For the port, use 14240.
134 * For the path, use `/api/ping`.
135 
136 Lastly, we need to set up session affinity for our load balancer. This is outlined in GCP documentation here:https://cloud.google.com/load-balancing/docs/https#session_affinity[External HTTP(S) Load Balancing overview  |  Google Cloud]
137 
138 After successfully creating the load balancer, you should now be able to access GraphStudio from the frontend IP associated with the load balancer.
